/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\nclient<llm> GLM4Flash {\n  provider openai-generic\n  options {\n    model \"glm-4-flash\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n  }\n}\n\nclient<llm> GLM45Flash {\n  provider openai-generic\n  options {\n    model \"glm-4.5-flash\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n  }\n}\n\nclient<llm> GLM45Air {\n  provider openai-generic\n  options {\n    model \"glm-4.5-air\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n  }\n}\n\nclient<llm> GLMZ1Flash {\n  provider openai-generic\n  options {\n    model \"glm-z1-flash\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n  }\n}\n\nclient<llm> GLM4Air {\n  provider openai-generic\n  options {\n    model \"glm-4-air\"\n    api_key env.GLM_API_KEY\n    base_url \"https://open.bigmodel.cn/api/paas/v4\"\n  }\n}\n\nclient<llm> QWen3 {\n  provider openai-generic\n  options {\n    model \"qwen-plus-latest\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}\n\nclient<llm> QWenFlash {\n  provider openai-generic\n  options {\n    model \"qwen-flash\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}\n\n\n\nclient<llm> QWen27binstruct {\n  provider openai-generic\n  options {\n    model \"qwen2-7b-instruct\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}\n\n\nclient<llm> QWen25_7binstruct {\n  provider openai-generic\n  options {\n    model \"qwen2.5-7b-instruct\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}\n\nclient<llm> QWen25_14binstruct {\n  provider openai-generic\n  options {\n    model \"qwen2.5-14b-instruct\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}\n\nclient<llm> QWen25_32binstruct {\n  provider openai-generic\n  options {\n    model \"qwen2.5-32b-instruct\"\n    api_key env.ALIBABA_API_KEY\n    base_url \"https://dashscope.aliyuncs.com/compatible-mode/v1/\"\n    enable_thinking false\n  }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../src\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.213.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "type.baml": "class WikiSearchParamsBaml {\n    language_code string\n    search_query string\n    number_of_results int\n}",
}
export const getBamlFiles = () => {
    return fileMap;
}