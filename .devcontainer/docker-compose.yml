version: '3.8'

services:
  app:
    build:
      context: .
      dockerfile: DockerFile
    volumes:
      - ..:/workspace:cached
    environment:
      - NODE_ENV=development
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_URL_API_KEY=
    command: sleep infinity
    ports:
      - "3000:3000"
      - "8000:8000"
    networks:
      - app-network
    depends_on:
      - elasticsearch

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:9.1.3
    container_name: container-es
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - http.cors.enabled=true
      - http.cors.allow-origin="*"
      - cluster.routing.allocation.disk.watermark.low=85%
      - cluster.routing.allocation.disk.watermark.high=90%
      - cluster.routing.allocation.disk.watermark.flood_stage=95%
    volumes:
      - es-data:/usr/share/elasticsearch/data
    ports:
      - "9200:9200"
      - "9300:9300"
    networks:
      - app-network
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped

  kibana:
    image: docker.elastic.co/kibana/kibana:9.1.3
    container_name: kibana-dev
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - SERVER_NAME=kibana
      # - XPACK_ENCRYPTEDSAVEDOBJECTS_ENCRYPTIONKEY=${KIBANA_ENCRYPTION_KEY:-some-default-key}
    ports:
      - "5601:5601"
    networks:
      - app-network
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped

  mongodb:
    image: mongo:latest
    restart: unless-stopped
    ports:
      - "27017:27017"
    volumes:
      - mongodb-data:/data/db
    networks:
      - app-network

  crawl4ai:
    image: unclecode/crawl4ai:latest
    restart: unless-stopped
    ports:
      - "11235:11235"
    networks:
      - app-network

  kafka:
    image: apache/kafka:4.1.0
    restart: unless-stopped
    ports:
      - "9092:9092"
    environment:
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=controller,broker
      - KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093
      - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
      - KAFKA_NUM_NETWORK_THREADS=3
      - KAFKA_NUM_IO_THREADS=8
      - KAFKA_SOCKET_SEND_BUFFER_BYTES=102400
      - KAFKA_SOCKET_RECEIVE_BUFFER_BYTES=102400
      - KAFKA_SOCKET_REQUEST_MAX_BYTES=104857600
    networks:
      - app-network
  rabbitmq:
    image: rabbitmq:3.13.6-management
    ports:
      - "5672:5672"
      - "8080:15672"
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=admin123
      - RABBITMQ_DEFAULT_VHOST=my_vhost
    volumes:
      - rabbitmq-data:/var/lib/rabbitmq
volumes:
  es-data:
  mongodb-data:
  rabbitmq-data:

networks:
  app-network:
    driver: bridge